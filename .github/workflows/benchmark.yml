name: Performance Benchmarks

on:
  push:
    branches:
      - master
  pull_request:
    branches:
      - master

jobs:
  benchmark:
    name: Run performance benchmarks
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5

      - name: Install uv
        uses: astral-sh/setup-uv@v6

      - name: Set up Python 3.14
        uses: actions/setup-python@v5
        with:
          python-version: '3.14'

      - name: Install dependencies
        run: uv sync

      # Cache benchmark results
      - name: Cache benchmark results
        uses: actions/cache@v4
        with:
          path: .benchmarks
          key: benchmark-results-${{ runner.os }}-${{ github.ref_name }}
          restore-keys: |
            benchmark-results-${{ runner.os }}-master
            benchmark-results-${{ runner.os }}-

      # On master branch: save baseline results
      - name: Run benchmarks and save baseline
        if: github.ref == 'refs/heads/master'
        run: |
          uv run --no-sync pytest bench \
            --benchmark-only \
            --benchmark-autosave \
            --benchmark-sort=name

      # On PRs: compare against baseline and fail if degraded
      - name: Run benchmarks and compare
        if: github.event_name == 'pull_request'
        run: |
          if [ -z "$(uv run --no-sync pytest-benchmark list)" ]; then
            echo "No baseline found, skip the benchmark"
            exit
          fi

          uv run --no-sync pytest bench \
              --benchmark-only \
              --benchmark-compare \
              --benchmark-compare-fail=mean:5% \
              --benchmark-sort=name

